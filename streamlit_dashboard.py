import streamlit as st
import pandas as pd
from azure.storage.blob import BlobServiceClient
from io import StringIO, BytesIO
import plotly.express as px
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import skew, kurtosis

st.set_page_config(layout="wide", page_title="Sentiment Dashboard", page_icon="üìä")


# ========================
# Azure Blob Setup
# ========================
AZURE_CONNECTION_STRING = st.secrets["AZURE_CONNECTION_STRING"]
CONTAINER_NAME = "visualizationdata"

@st.cache_data(ttl=86400)
def load_blob_csv(blob_name, container=CONTAINER_NAME):
    blob_service_client = BlobServiceClient.from_connection_string(AZURE_CONNECTION_STRING)
    blob_client = blob_service_client.get_blob_client(container=container, blob=blob_name)
    blob_data = blob_client.download_blob().readall()
    return pd.read_csv(StringIO(blob_data.decode('utf-8')))

# ========================
# Load Raw Master Data
# ========================
df_youtube_master = load_blob_csv("youtube_master_comments.csv", container="datayoutube")
df_news_master = load_blob_csv("google_news_master_articles.csv", container="datanews")
df_reddit_master = load_blob_csv("reddit_master_comments.csv", container="datareddit")

# ========================
# Load Snapshot News Data (hidden)
# ========================
def list_snapshot_blobs():
    blob_service_client = BlobServiceClient.from_connection_string(AZURE_CONNECTION_STRING)
    container_client = blob_service_client.get_container_client("snapshots")
    return [blob.name for blob in container_client.list_blobs() if blob.name.startswith("google_news_articles") and blob.name.endswith(".csv")]

snapshot_blobs = list_snapshot_blobs()

df_snapshots_combined = pd.DataFrame()
for blob_name in snapshot_blobs:
    df_temp = load_blob_csv(blob_name, container="snapshots")
    df_temp["snapshot_file"] = blob_name
    df_snapshots_combined = pd.concat([df_snapshots_combined, df_temp], ignore_index=True)

# ========================
# File Mappings by Source
# ========================
blob_map = {
    "Reddit": {
        "analysis": "reddit_analysis.csv",
        "timeseries": "reddit_time_series.csv",
        "wordcloud": "reddit_post_word_cloud.csv"
    },
    "YouTube": {
        "analysis": "youtube_analysis.csv",
        "timeseries": "youtube_time_series.csv",
        "wordcloud": "youtube_word_cloud.csv"
    },
    "Google News": {
        "analysis": "google_news_analysis.csv",
        "timeseries": "google_news_time_series.csv",
        "wordcloud": "google_news_word_cloud.csv"
    }
}

# ========================
# Sidebar: Data Source Selection
# ========================
st.sidebar.header("üéõÔ∏è Controls")
source_options = list(blob_map.keys()) + ["Combined"]
source = st.sidebar.selectbox("Choose data source", source_options)

# ========================
# Safety Check and Basic UI
# ========================
if not source:
    st.warning("Please select a data source from the sidebar.")
    st.stop()

st.title("üìä Sentiment Analysis Dashboard")
st.markdown("This dashboard visualizes sentiment trends across Reddit, YouTube, and Google News.")
st.info(f"You are viewing: **{source}** data")

# ========================
# Load Selected Analysis Data
# ========================
if source != "Combined":
    blobs = blob_map[source]
    df_analysis = load_blob_csv(blobs["analysis"])
    df_wordcloud = load_blob_csv(blobs["wordcloud"])
else:
    dfs = []
    df_wordclouds = []
    for src, paths in blob_map.items():
        temp_df = load_blob_csv(paths["analysis"])
        temp_df["source"] = src
        dfs.append(temp_df)
        wc_temp = load_blob_csv(paths["wordcloud"])
        wc_temp["source"] = src
        df_wordclouds.append(wc_temp)
    df_analysis = pd.concat(dfs, ignore_index=True)
    df_wordcloud = pd.concat(df_wordclouds, ignore_index=True)

# ========================
# Preprocessing
# ========================
if 'comment_published_at' in df_analysis.columns:
    df_analysis['date'] = pd.to_datetime(df_analysis['comment_published_at'], errors='coerce')
elif 'published_at' in df_analysis.columns:
    df_analysis['date'] = pd.to_datetime(df_analysis['published_at'], errors='coerce')
else:
    df_analysis['date'] = pd.NaT

category_label_map = {
    "category_funding_cost": "Funding Cost",
    "category_construction_progress": "Construction Progress",
    "category_politics_governance": "Politics & Governance",
    "category_environmental_impact": "Environmental Impact",
    "category_economic_impact": "Economic Impact",
    "category_alternatives_competition": "Alternatives & Competition",
    "category_regional_impact": "Regional Impact",
    "category_public_opinion": "Public Opinion",
    "category_international_comparisons": "International Comparisons"
}

category_cols = [col for col in df_analysis.columns if col in category_label_map]

if 'date' in df_analysis.columns and df_analysis['date'].notna().any():
    date_range = st.sidebar.date_input("Date range", [df_analysis['date'].min(), df_analysis['date'].max()])
    filtered_df = df_analysis[(df_analysis['date'] >= pd.to_datetime(date_range[0])) & (df_analysis['date'] <= pd.to_datetime(date_range[1]))]
else:
    st.warning("‚ö†Ô∏è No usable date column found. Displaying all records.")
    filtered_df = df_analysis

if filtered_df.empty:
    st.warning("‚ö†Ô∏è No comments available for the selected date range.")
    st.stop()

# Continue with: UI metrics, trend line, smoothing, skew/kurtosis, correlation heatmap, category averages, word cloud, heatmap, summary
# ========================
# UI Metrics
# ========================
st.metric("Total Comments", len(filtered_df))
st.divider()

# ========================
# Trend and Smoothing
# ========================
st.subheader("üìà Sentiment Trend Over Time")
category_reverse_map = {v: k for k, v in category_label_map.items()}

multi_select_mode = st.toggle("Compare multiple categories", value=False)

if multi_select_mode:
    selected_labels = st.multiselect("Select categories to compare", [category_label_map[c] for c in category_cols], default=[category_label_map[category_cols[0]]])
    selected_categories = [category_reverse_map[label] for label in selected_labels]
else:
    selected_label = st.selectbox("Select category to view trend", [category_label_map[c] for c in category_cols], key="trend_category_select")
    selected_categories = [category_reverse_map[selected_label]]

smoothing_option = st.selectbox("Smoothing", ["None", "7-Day Moving Average", "Monthly Average"])

trend_df = filtered_df.copy()
trend_df['date'] = pd.to_datetime(trend_df['date'])
trend_df = trend_df.dropna(subset=['date'])

trend_lines = []
for cat in selected_categories:
    temp = trend_df.copy()
    if source != "Combined":
        temp['source'] = source
    grouped = temp.groupby([temp['date'].dt.date, 'source'])[cat].mean().reset_index(name='value')
    grouped['date'] = pd.to_datetime(grouped['date'])
    grouped['category'] = category_label_map[cat]
    trend_lines.append(grouped)

trend = pd.concat(trend_lines, ignore_index=True)

if smoothing_option == "7-Day Moving Average":
    trend = trend.set_index('date').groupby(['category', 'source']).rolling('7D').mean().reset_index()
elif smoothing_option == "Monthly Average":
    trend = trend.set_index('date').groupby(['category', 'source']).resample('M').mean().reset_index()

fig_trend = px.line(trend, x='date', y='value', color='category' if multi_select_mode else 'source',
                    title="Sentiment Trend Over Time")
st.plotly_chart(fig_trend, use_container_width=True)
st.divider()

# ========================
# Advanced Stats: Skewness and Kurtosis
# ========================
st.subheader("üìà Sentiment Distribution Analysis")
if multi_select_mode:
    st.info("üìå Skewness & kurtosis shown for first selected category.")
    selected_scores = filtered_df[selected_categories[0]].dropna()
    display_label = category_label_map[selected_categories[0]]
else:
    selected_scores = filtered_df[selected_categories[0]].dropna()
    display_label = selected_label

sentiment_skew = skew(selected_scores)
sentiment_kurt = kurtosis(selected_scores)

col1, col2 = st.columns(2)
col1.metric("Skewness", f"{sentiment_skew:.3f}")
col2.metric("Kurtosis", f"{sentiment_kurt:.3f}")

fig_dist = px.histogram(selected_scores, nbins=50, marginal="violin", title=f"Sentiment Distribution for {display_label}", labels={"value": "Sentiment Score"})
st.plotly_chart(fig_dist, use_container_width=True)
st.divider()

# ========================
# Correlation Heatmap
# ========================
if len(category_cols) > 1:
    st.subheader("üìâ Sentiment Category Correlation")
    corr = filtered_df[category_cols].corr()
    corr.columns = [category_label_map.get(c, c) for c in corr.columns]
    corr.index = [category_label_map.get(c, c) for c in corr.index]
    fig_corr = px.imshow(corr, text_auto=True, color_continuous_scale='RdBu_r', aspect="auto", title="Category Sentiment Correlation Matrix")
    st.plotly_chart(fig_corr, use_container_width=True)
st.divider()

# ========================
# Category Occurrence Count
# ========================
st.subheader("üìä Count of Posts Tagged by Category")
category_counts = filtered_df[category_cols].gt(0).sum().reset_index()
category_counts.columns = ["Category", "Count"]
category_counts["Category"] = category_counts["Category"].map(category_label_map)
fig_count = px.bar(category_counts, x="Category", y="Count", color="Count",
                   title="Number of Mentions per Sentiment Category", color_continuous_scale="Blues")
fig_count.update_layout(showlegend=False)
st.plotly_chart(fig_count, use_container_width=True)
st.divider()

# ========================
# Average Sentiment per Category
# ========================
st.subheader("üìä Average Sentiment per Category")
avg_scores = filtered_df[category_cols].rename(columns=category_label_map).mean().reset_index()
avg_scores.columns = ['Category', 'Average Sentiment']
fig_avg = px.bar(avg_scores, x='Category', y='Average Sentiment', color='Category', color_discrete_sequence=px.colors.sequential.Blues)
fig_avg.update_layout(showlegend=False)
fig_avg.update_layout(
    title="Mean Sentiment Score per Category",
    xaxis_title="Sentiment Category",
    yaxis_title="Average Sentiment"
)"Mean Sentiment Score per Category", color_continuous_scale='RdYlGn')
st.plotly_chart(fig_avg, use_container_width=True)
st.divider()

# ========================
# Word Cloud Viewer
# ========================
st.subheader("‚òÅÔ∏è Word Cloud Viewer")
stopwords = set(STOPWORDS)
stopwords.update(["thing", "like", "people", "just", "really", "got", "youre", "shit"])

if 'word' in df_wordcloud.columns and 'count' in df_wordcloud.columns:
    clean_df = df_wordcloud[~df_wordcloud['word'].str.lower().isin(stopwords)]
    word_freq = dict(zip(clean_df['word'], clean_df['count']))

    if word_freq:
        wordcloud = WordCloud(width=800, height=400, background_color="white", stopwords=stopwords).generate_from_frequencies(word_freq)
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis("off")
        st.pyplot(fig)

        buf = BytesIO()
        fig.savefig(buf, format="png")
        buf.seek(0)

        st.download_button(label="üì• Download Word Cloud PNG", data=buf, file_name=f"{source.lower()}_wordcloud.png", mime="image/png")
    else:
        st.info("No words available to generate word cloud.")
else:
    st.warning("‚ö†Ô∏è Word cloud file must contain 'word' and 'count' columns.")
st.divider()

# ========================
# Export Summary Report
# ========================
st.subheader("üìÑ Export Summary Report")
summary_text = f"""
Sentiment Dashboard Summary Report - {source}
Date Range: {date_range[0]} to {date_range[1]}
Total Comments: {len(filtered_df)}

Average Sentiment by Category:
"""
for index, row in avg_scores.iterrows():
    line = f"- {row['Category']}: {row['Average Sentiment']:.3f}"
    summary_text += line

summary_bytes = BytesIO(summary_text.encode('utf-8'))
st.download_button(label="üì• Download Text Summary", data=summary_bytes, file_name=f"{source.lower()}_sentiment_summary.txt", mime="text/plain")
